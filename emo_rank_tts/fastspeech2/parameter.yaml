##############################################
# 1. Paths
##############################################
path:
  data_path:          '/workspace/data/EmoV-DB'
  corpus_path:        '/workspace/montreal_forced_aligner/corpus'
  textgrid_path:      '/workspace/montreal_forced_aligner/aligned'
  preprocessed_path:  '/workspace/preprocessed'
  experiment_path:    '/workspace/experiments/fastspeech2'
  model_path:         '/workspace/experiments/fastspeech2/exp_4/best_model.pth'
  vocoder_path:       '/workspace/pretrained_models/tts-hifigan-libritts-16kHz'
  intensity_path:     '/workspace/experiments/rank_model/exp_5/intensity.npy'


##############################################
# 2. Preprocessing
##############################################
preprocessing:
  noise_symbol:       ' [noise] '
  speakers:           ['bea', 'jenie', 'josh', 'sam']
  emotions:           ['neutral', 'amused', 'angry', 'disgusted', 'sleepy']
  sil_phones:         ['sil', 'spn', 'sp', '']
  pitch_averaging:    False
  energy_averaging:   False
  match_transcript:   False


##############################################
# 3. Audio (optimized for vocoder)
##############################################
audio:
  sampling_rate:      16000
  hop_length:         256
  win_length:         1024
  n_fft:              1024
  n_mels:             80
  f_min:              0.0
  f_max:              8000.0


##############################################
# 4. Training
##############################################
train:
  n_epochs:           1000
  max_iterations:     250000
  batch_size:         8
  learning_rate:      0.0001
  patience:           10


##############################################
# 5. Model
##############################################
model:
  rank_model:
    n_encoder_layers:   4
    n_heads:            2
    hidden_dim:         256
    kernel_size:        9
    dropout:            0.1
    alpha:              0.1
    beta:               1.0
  fastspeech2:
    enc_num_layers: 6
    enc_num_head: 2
    enc_d_model: 384
    enc_ffn_dim: 1536
    enc_k_dim: 384
    enc_v_dim: 384
    enc_dropout: 0.1
    dec_num_layers: 6
    dec_num_head: 2
    dec_d_model: 384
    dec_ffn_dim: 1536
    dec_k_dim: 384
    dec_v_dim: 384
    dec_dropout: 0.1
    normalize_before: False
    ffn_type: '1dcnn'
    ffn_cnn_kernel_size_list: [9, 1]
    n_char: 95
    n_mels: 80
    postnet_embedding_dim: 512
    postnet_kernel_size: 5
    postnet_n_convolutions: 5
    postnet_dropout: 0.5
    padding_idx: 0
    dur_pred_kernel_size: 3
    pitch_pred_kernel_size: 3
    energy_pred_kernel_size: 3
    variance_predictor_dropout: 0.5


##############################################
# 6. Loss
##############################################
loss:
  log_scale_durations: True
  ssim_loss_weight: 1.0
  duration_loss_weight: 1.0
  pitch_loss_weight: 1.0
  energy_loss_weight: 1.0
  mel_loss_weight: 1.0
  postnet_mel_loss_weight: 1.0
  # aligner_loss_weight: 1.0
  spn_loss_weight: 0.0
  spn_loss_max_epochs: 1


##############################################
# 7. Miscellaneous
##############################################
misc:
  markers:            ['o', '^', 's', 'd']
  colors:             ['#7C00FE', '#F9E400', '#FFAF00', '#F5004F', '#00B2A9']


##############################################
# 8. Inference
##############################################
inference:
  mode:               'bucketize'     # 'bucketize' or 'inference'
  best_pth_path:      '/workspace/experiments/rank_model/exp_5/best_model.pth'
  bucket_size:        3

  speaker:            'jenie'
  emotion:            'neutral'
  text:               'Hello, my name is ryu jong moon'
  intensity_level:    2